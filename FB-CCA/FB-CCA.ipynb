{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EEG Feature Extraction and Classification Using FB-CCA\n",
        "\n",
        "This notebook focuses on EEG feature extraction and classification using Filter Bank Canonical Correlation Analysis (FB-CCA), a method particularly effective in SSVEP BCIs.\n",
        "\n",
        "### Why Use Temporal Features (like CCA) Instead of Spectral Features?\n",
        "While traditional spectral methods (e.g., power spectral density) analyze EEG frequency components independently, temporal feature extraction methods like Canonical Correlation Analysis (CCA) leverage correlations between EEG signals and predefined reference signals across multiple channels. This approach effectively captures spatial and temporal coherence patterns inherent in EEG data, providing robustness against noise and improving discriminative performance.\n",
        "\n",
        "### What is FB-CCA and Why Might it Work?\n",
        "Filter Bank CCA (FB-CCA) enhances the standard CCA by decomposing EEG data into multiple sub-band frequency components (filter banks). Each frequency band undergoes separate CCA processing, and their outputs are combined, typically through weighted averaging. This multiband approach exploits frequency-specific information more comprehensively, significantly improving classification accuracy, especially in noisy environments or with individual subject variations.\n",
        "\n",
        "### Dataset and Experimental Setup\n",
        "The dataset utilized here currently includes EEG recordings from 11 subjects SSVEP stimulation. Each subject's EEG data is segmented into epochs corresponding to specific stimulus frequencies, allowing evaluation of the FB-CCA method's effectiveness in classifying these frequencies. The experimental details, including stimulus conditions and EEG recording protocols, are described in a separate documentation file.\n",
        "\n",
        "This notebook specifically demonstrates the preprocessing, FB-CCA feature extraction, and classification workflows, emphasizing the temporal coherence captured by FB-CCA.\n",
        "\n",
        "### Classification Methods Compared\n",
        "Initially, we will classify EEG trials simply by selecting the stimulus frequency that yields the highest CCA correlation coefficient per trial. This baseline approach will be compared with training a simple classifier (KNN) on extracted CCA features. Although KNN might not be the most efficient classifier, it is chosen here due to its simplicity and minimal hyperparameter tuning requirements, allowing to focus on feature extraction method instead. Finally, the performance of these methods will be compared against the enhanced FB-CCA approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "qajcMLjnTTqC",
        "outputId": "9ccdf8ea-3aea-4b7d-e845-47fe80275513"
      },
      "outputs": [],
      "source": [
        "from dataset import EEGDataset\n",
        "\n",
        "data_path = r\"path\\to\\your\\dataset\"\n",
        "\n",
        "# Initialize dataset loader\n",
        "dataset = EEGDataset(data_path)\n",
        "print(dir(dataset))  # This should list all available methods\n",
        "# Load all subjects\n",
        "dataset.load_all_subjects()\n",
        "print(\"Subjects loaded:\", dataset.raw_data.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# After loading the data, we preprocess it with the following steps:\n",
        "\n",
        " - EEG data re-referencing using channels A1 and A2 (mastoid references) to reduce noise and common artifacts.\n",
        " - Filtering and resampling EEG signals to a standard sampling frequency (256 Hz) to ensure consistency.\n",
        " - Removing irrelevant frequencies and noise through bandpass filtering.\n",
        " - Segmenting the EEG data into epochs corresponding to each stimulation event, specifically focusing on 4-second intervals from stimulus onset for subsequent analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from preprocessing import EEGPreprocessor\n",
        "\n",
        "# Initialize preprocessing\n",
        "preprocessor = EEGPreprocessor(sfreq=256, l_freq=6.0, h_freq=80.0, invalid_keys=['100', '99', '36'])\n",
        "\n",
        "# Preprocess EEG data\n",
        "epochs_data = {}\n",
        "for subject, raw in dataset.raw_data.items():\n",
        "    epochs = preprocessor.create_epochs_from_raw(raw, tmin=0, tmax=4)\n",
        "\n",
        "    if epochs:  # Only add epochs if valid\n",
        "        epochs_data[subject] = epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Extraction and Label Standardization\n",
        "\n",
        "In this step, we:\n",
        "\n",
        "- Ensure consistent labeling across all subjects by creating a standardized mapping based on the first subject's event labels.\n",
        "- Extract CCA features from EEG epochs for each subject. Currently, the extraction uses one harmonic, but increasing the number of harmonics could potentially enhance classification accuracy in other contexts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standardized Label Mapping (from first subject): {1: 6, 2: 8, 3: 10, 4: 12, 5: 14, 6: 20, 7: 25, 8: 30, 9: 0.1}\n",
            "Subject: S1 | Features shape: (182, 9) | Labels: [9 2 1 6 8]\n",
            "Subject: S10 | Features shape: (184, 9) | Labels: [3 2 5 7 4]\n",
            "Subject: S11 | Features shape: (183, 9) | Labels: [9 6 2 1 3]\n",
            "Subject: S2 | Features shape: (182, 9) | Labels: [4 1 2 9 3]\n",
            "Subject: S3 | Features shape: (182, 9) | Labels: [9 6 2 1 3]\n",
            "Subject: S4 | Features shape: (183, 9) | Labels: [2 4 5 9 1]\n",
            "Subject: S5 | Features shape: (185, 9) | Labels: [3 6 4 1 2]\n",
            "Subject: S6 | Features shape: (185, 9) | Labels: [9 2 1 6 8]\n",
            "Subject: S7 | Features shape: (180, 9) | Labels: [6 3 7 8 5]\n",
            "Subject: S8 | Features shape: (183, 9) | Labels: [2 9 8 3 6]\n",
            "Subject: S9 | Features shape: (184, 9) | Labels: [4 9 2 6 5]\n"
          ]
        }
      ],
      "source": [
        "from feature_extraction import FeatureExtractor\n",
        "from classifier import EEGClassifier\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "# Storage for features and labels per subject\n",
        "features_by_subject = {}\n",
        "labels_by_subject = {}\n",
        "\n",
        "# Define stimulation frequencies\n",
        "stim_frequencies = [6, 8, 10, 12, 14, 20, 25, 30, 0.1]  # Stimutation flicker frequencies\n",
        "\n",
        "# Get standardized event mapping from the first subject\n",
        "first_subject = next(iter(epochs_data.keys()))\n",
        "first_subject_labels = epochs_data[first_subject].events[:, -1]  # Extract labels from the first subject\n",
        "unique_labels_first_subject = np.unique(first_subject_labels)\n",
        "\n",
        "# Create a mapping: {original label â†’ standardized label (stimulation frequency)}\n",
        "label_mapping = {orig_label: stim_frequencies[idx] for idx, orig_label in enumerate(unique_labels_first_subject)}\n",
        "\n",
        "print(\"Standardized Label Mapping (from first subject):\", label_mapping)\n",
        "\n",
        "# Initialize Feature Extractor (Using CCA with Filterbank)\n",
        "feature_extractor = FeatureExtractor(method=\"CCA\", sfreq=256, num_harmonics=2)\n",
        "\n",
        "for subject, epochs in epochs_data.items():\n",
        "    if epochs is None:\n",
        "        continue\n",
        "\n",
        "    X = feature_extractor.extract_features(epochs, stim_frequencies)\n",
        "    y = epochs.events[:, -1]\n",
        "\n",
        "    features_by_subject[subject] = X\n",
        "    labels_by_subject[subject] = y\n",
        "\n",
        "    print(f\"Subject: {subject} | Features shape: {X.shape} | Labels: {y[:5]}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Classification Results and Discussion\n",
        "\n",
        "We now evaluate the performance of two classification methods on our EEG data:\n",
        "\n",
        "**1. Max CCA Feature Selection**\n",
        "\n",
        "In this unsupervised approach, each EEG trial is independently classified by selecting the stimulus frequency with the highest CCA correlation coefficient. This simple method achieves an accuracy of **53.3%**, slightly above chance level with several obvious limitations:\n",
        "\n",
        "- **6 Hz** stimulation trials frequently show stronger responses in the first harmonic (**12 Hz**), causing misclassification.\n",
        "- Conversely, trials at **20 Hz** are often incorrectly classified as **10 Hz** due to similar harmonic confusion.\n",
        "- Many trials are incorrectly labeled as **non-stimuli (0.1 Hz)** due to unexpectedly high correlation with baseline reference signals.\n",
        "\n",
        "**2. KNN Classification (Leave-Subject-Out Cross-Validation)**\n",
        "\n",
        "This supervised approach involves training a KNN classifier on EEG data from all subjects except one, which serves as the test set. This methodology simulates real-world scenarios where no data is initially available from new BCI users. Although KNN is a simple classifier chosen for ease of use and minimal hyperparameter tuning, it significantly improves classification accuracy to **63.7%**. Notably:\n",
        "\n",
        "- The number of trials misclassified as harmonics or non-stimuli is reduced.\n",
        "- Some subjects achieve individual accuracies exceeding **86%**, highlighting the effectiveness of supervised learning even with simple classifiers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classifying subject S1 with 182 trials.\n",
            "Classifying subject S10 with 184 trials.\n",
            "Classifying subject S11 with 183 trials.\n",
            "Classifying subject S2 with 182 trials.\n",
            "Classifying subject S3 with 182 trials.\n",
            "Classifying subject S4 with 183 trials.\n",
            "Classifying subject S5 with 185 trials.\n",
            "Classifying subject S6 with 185 trials.\n",
            "Classifying subject S7 with 180 trials.\n",
            "Classifying subject S8 with 183 trials.\n",
            "Classifying subject S9 with 184 trials.\n",
            "\n",
            "Confusion Matrix (Max-CCA):\n",
            "[[ 71   7   4 123   2   0   0   0  12]\n",
            " [ 13 172  12  27   8   5   1   1  19]\n",
            " [  7   3 176   7   4  12   0   0  11]\n",
            " [  6   1   4 192   3   0   0   0  14]\n",
            " [  8   4   4   5 183   1   0   1  12]\n",
            " [  6   5   9  18   5 152   2   1  23]\n",
            " [  5   4 116  17   1  28  29   2  17]\n",
            " [ 26  21  27  36   9   3   1  78  18]\n",
            " [ 24  51  57  45  11   8   1   2  20]]\n",
            "Overall Max-CCA Classification Accuracy: 0.5330\n",
            "Testing on subject S1, training on remaining subjects.\n",
            "Subject S1 Accuracy: 0.6538\n",
            "Confusion Matrix for Subject S1:\n",
            "[[ 9  1  1  4  0  0  0  1  4]\n",
            " [ 0 16  1  1  0  0  0  1  3]\n",
            " [ 0  0 18  0  0  1  0  0  1]\n",
            " [ 2  0  0 17  0  0  0  0  1]\n",
            " [ 0  0  0  0 19  0  1  0  0]\n",
            " [ 0  2  2  0  1 12  0  1  2]\n",
            " [ 1  0  0  3  1  0 14  0  1]\n",
            " [ 2  3  0  2  0  0  1  6  6]\n",
            " [ 1  3  0  4  1  1  1  1  8]]\n",
            "Testing on subject S10, training on remaining subjects.\n",
            "Subject S10 Accuracy: 0.1685\n",
            "Confusion Matrix for Subject S10:\n",
            "[[ 0  8  0  0  0  0  0  4  7]\n",
            " [ 1  7  0  0  0  0  1 10  6]\n",
            " [ 1  6  0  0  1  0  2  5  5]\n",
            " [ 3  7  0  0  0  0  0  2  8]\n",
            " [ 1  6  0  0  2  0  0  3  8]\n",
            " [ 2  3  0  0  0  0  2  6  7]\n",
            " [ 0  9  0  0  0  0  3  3  5]\n",
            " [ 1  1  0  0  0  0  2 13  3]\n",
            " [ 0 11  0  0  0  0  1  2  6]]\n",
            "Testing on subject S11, training on remaining subjects.\n",
            "Subject S11 Accuracy: 0.7268\n",
            "Confusion Matrix for Subject S11:\n",
            "[[16  1  0  0  0  0  1  1  1]\n",
            " [ 1 21  0  1  0  0  0  0  2]\n",
            " [ 0  1 16  1  1  0  0  0  1]\n",
            " [ 1  0  0 15  0  1  1  0  2]\n",
            " [ 0  0  0  0 16  1  0  1  2]\n",
            " [ 0  1  0  0  1 16  0  1  1]\n",
            " [ 0  0  1  0  0  1 15  1  1]\n",
            " [ 0  0  0  0  1  1  1 14  2]\n",
            " [ 2  6  1  1  3  1  0  2  4]]\n",
            "Testing on subject S2, training on remaining subjects.\n",
            "Subject S2 Accuracy: 0.8626\n",
            "Confusion Matrix for Subject S2:\n",
            "[[20  0  0  0  0  0  0  0  0]\n",
            " [ 0 20  1  1  0  0  0  0  0]\n",
            " [ 0  0 20  0  0  0  0  0  0]\n",
            " [ 0  0  0 20  0  0  0  0  0]\n",
            " [ 0  0  0  0 20  0  0  0  0]\n",
            " [ 0  0  0  0  0 20  0  0  0]\n",
            " [ 0  0  1  0  0  1 18  0  0]\n",
            " [ 2  0  1  0  0  1  0 16  0]\n",
            " [ 0  6  0  4  0  1  6  0  3]]\n",
            "Testing on subject S3, training on remaining subjects.\n",
            "Subject S3 Accuracy: 0.8571\n",
            "Confusion Matrix for Subject S3:\n",
            "[[20  0  0  0  0  0  0  0  0]\n",
            " [ 0 19  0  1  0  0  1  1  0]\n",
            " [ 0  0 20  0  0  0  0  0  0]\n",
            " [ 0  0  0 20  0  0  0  0  0]\n",
            " [ 0  0  0  0 20  0  0  0  0]\n",
            " [ 0  0  0  0  0 20  0  0  0]\n",
            " [ 0  0  2  0  0  0 14  2  2]\n",
            " [ 0  1  0  0  0  0  1 14  4]\n",
            " [ 1  3  2  1  1  1  2  0  9]]\n",
            "Testing on subject S4, training on remaining subjects.\n",
            "Subject S4 Accuracy: 0.3115\n",
            "Confusion Matrix for Subject S4:\n",
            "[[ 9  3  0  0  1  0  1  2  4]\n",
            " [ 0  8  0  0  1  0  0  3 11]\n",
            " [ 1  2  3  0  0  2  4  4  4]\n",
            " [ 6  2  0  3  0  0  1  4  4]\n",
            " [ 2  1  0  0  7  0  0  7  3]\n",
            " [ 0  3  0  0  0  1  5  1 10]\n",
            " [ 1  1  0  0  0  0 10  3  5]\n",
            " [ 0  6  0  0  0  0  3  6  5]\n",
            " [ 0  1  0  0  1  0  3  5 10]]\n",
            "Testing on subject S5, training on remaining subjects.\n",
            "Subject S5 Accuracy: 0.7892\n",
            "Confusion Matrix for Subject S5:\n",
            "[[19  0  0  1  0  0  0  0  0]\n",
            " [ 2 19  0  0  0  0  1  0  3]\n",
            " [ 0  0 15  0  0  0  5  0  0]\n",
            " [ 8  0  0 10  0  0  0  2  0]\n",
            " [ 0  0  0  0 20  0  0  0  0]\n",
            " [ 0  0  1  0  0 19  0  0  0]\n",
            " [ 0  0  0  0  0  0 20  0  0]\n",
            " [ 0  0  0  0  0  0  0 18  2]\n",
            " [ 3  2  0  0  0  1  3  5  6]]\n",
            "Testing on subject S6, training on remaining subjects.\n",
            "Subject S6 Accuracy: 0.7135\n",
            "Confusion Matrix for Subject S6:\n",
            "[[10  0  0 10  0  0  0  0  0]\n",
            " [ 5 11  0  4  0  0  1  1  3]\n",
            " [ 0  0 16  0  0  4  0  0  0]\n",
            " [ 0  0  1 19  0  0  0  0  0]\n",
            " [ 0  0  0  0 20  0  0  0  0]\n",
            " [ 0  0  0  0  0 20  0  0  0]\n",
            " [ 0  0  0  0  1  1 17  0  1]\n",
            " [ 0  3  0  1  2  0  0 12  2]\n",
            " [ 1  5  0  0  1  3  1  2  7]]\n",
            "Testing on subject S7, training on remaining subjects.\n",
            "Subject S7 Accuracy: 0.6667\n",
            "Confusion Matrix for Subject S7:\n",
            "[[17  0  1  0  0  1  0  0  1]\n",
            " [ 0 20  0  0  0  0  0  1  0]\n",
            " [ 0  1 19  0  0  0  0  0  0]\n",
            " [ 8  0  0 12  0  0  0  0  0]\n",
            " [ 0  1  0  0 18  0  0  0  0]\n",
            " [ 0  4  1  0  0 15  0  0  1]\n",
            " [ 0  1  4  0  0  1  9  0  5]\n",
            " [ 4  2  0  0  0  0  1  4  9]\n",
            " [ 2  6  3  1  0  0  1  0  6]]\n",
            "Testing on subject S8, training on remaining subjects.\n",
            "Subject S8 Accuracy: 0.8634\n",
            "Confusion Matrix for Subject S8:\n",
            "[[20  0  0  0  0  0  0  0  0]\n",
            " [ 0 18  1  0  0  0  0  1  3]\n",
            " [ 0  0 20  0  0  0  0  0  0]\n",
            " [ 0  0  0 20  0  0  0  0  0]\n",
            " [ 0  0  0  0 20  0  0  0  0]\n",
            " [ 0  0  2  0  0 18  0  0  0]\n",
            " [ 0  0  1  1  0  0 16  2  0]\n",
            " [ 0  1  0  0  0  0  1 17  1]\n",
            " [ 3  1  0  1  0  0  1  5  9]]\n",
            "Testing on subject S9, training on remaining subjects.\n",
            "Subject S9 Accuracy: 0.3967\n",
            "Confusion Matrix for Subject S9:\n",
            "[[13  0  1  4  0  1  0  0  1]\n",
            " [ 2 11  1  0  0  0  0  2  9]\n",
            " [ 1  3  7  3  1  2  2  1  0]\n",
            " [ 1  4  1  9  0  0  1  1  3]\n",
            " [ 3  0  0  1 10  0  0  1  4]\n",
            " [ 1  5  2  6  0  3  0  0  3]\n",
            " [ 1  2  0  6  0  0  7  1  3]\n",
            " [ 4  1  0  4  1  1  1  2  6]\n",
            " [ 1  2  0  2  0  0  4  0 11]]\n",
            "\n",
            "Overall Aggregated Confusion Matrix (KNN):\n",
            "[[153  13   3  19   1   2   2   8  18]\n",
            " [ 11 170   4   8   1   0   4  20  40]\n",
            " [  3  13 154   4   3   9  13  10  11]\n",
            " [ 29  13   2 145   0   1   3   9  18]\n",
            " [  6   8   0   1 172   1   1  12  17]\n",
            " [  3  18   8   6   2 144   7   9  24]\n",
            " [  3  13   9  10   2   4 143  12  23]\n",
            " [ 13  18   1   7   4   3  11 122  40]\n",
            " [ 14  46   6  14   7   8  23  22  79]]\n",
            "Average Leave-Subject-Out KNN Accuracy: 0.6373\n",
            "\n",
            "Final Results:\n",
            "Max-CCA Classification Accuracy: 0.5330\n",
            "KNN Classification Accuracy: 0.6373\n"
          ]
        }
      ],
      "source": [
        "# Initialize classifier\n",
        "classifier = EEGClassifier()\n",
        "\n",
        "# **Method 1: Max CCA Feature Selection**\n",
        "accuracy_maxcca, conf_matrix_maxcca = classifier.classify_max_cca(features_by_subject, labels_by_subject, stim_frequencies)\n",
        "\n",
        "# **Method 2: KNN Classification**\n",
        "accuracy_knn, conf_matrix_knn = classifier.classify_knn(features_by_subject, labels_by_subject)\n",
        "\n",
        "print(\"\\nFinal Results:\")\n",
        "print(f\"Max-CCA Classification Accuracy: {accuracy_maxcca:.4f}\")\n",
        "print(f\"KNN Classification Accuracy: {accuracy_knn:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "EEG visual analysis",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
